llm: gpt-4 #alternatives: llama3, llama2 not working since models do not support structured output
number_of_chunks: 10
llm_framework: openai
llama2: /Users/Kenneth/PycharmProjects/knowledgeGraph/models/llama-2-7b-chat.Q5_K_M.gguf
llama3: /Users/Kenneth/PycharmProjects/knowledgeGraph/models/Meta-Llama-3-8B.Q5_K_M.gguf
modelling_location: local
prompt: german_med_prompt
until_chunk: 1
